---
title: "Webscraping"
author: "Jan-Philipp Kolb"
date: "Wed Oct 14 11:19:52 2015"
output: slidy_presentation
---


```{r,echo=F,warning=F}
library(knitr)
Ex <- F
Ex1 <- T
```

## Das R-Paket `XML`

Gaston Sanchez - [Basics of XML and HTML](https://www.dropbox.com/s/eyd4t9h7n9fx0du/getting_web_data_r3_basics_xml_html.pdf?dl=0)

```{r}
# install.packages("XML")
library(XML)
```


Einlesen einer Tabelle mit der Funktion `readHTMLTable`:

Beispieldaten für die Bundesländer
```{r,eval=Ex1}
BLA_link <- "http://www.bernhard-gaul.de/wissen/bundeslaender.php"
BLA_tab <- readHTMLTable(BLA_link)
```

## Überblick über die Daten

```{r}
BLA_tab <- BLA_tab[[1]]
```


```{r,echo=F,eval=Ex1}
kable(BLA_tab)
```


## Daten bearbeiten

Die erste und 18. Zeile entfernen:

```{r}
BLA_tab <- BLA_tab[-c(1,18),-1]
```


## Die Daten editieren

```{r}
mean(BLA_tab[,2])
```

um dies zu ändern ist ein wenig Kosmetik notwendig:

```{r}
BLA_tab[,2] <- gsub(" ","",BLA_tab[,2])
BLA_tab[,2] <- gsub(",",".",BLA_tab[,2])
BLA_tab[,2] <- as.numeric(BLA_tab[,2])
```


```{r}
mean(BLA_tab[,2])
```


## Die weiteren Spalten bearbeiten

```{r}
BLA_tab[,3] <- as.numeric(gsub(" ","",BLA_tab[,3]))
BLA_tab[,4] <- as.numeric(gsub(" ","",BLA_tab[,4]))
```

Das Editing ist also aufwändiger als das eigentliche Scraping

## Das Paket `rvest`

```{r,eval=F}
install.packages("rvest")
```

```{r,eval=F}
library("rvest")

link <- "https://de.wikipedia.org/wiki/Liste_der_St%C3%A4dte_in_Finnland"

link_data <- read_html(link)

# parse the document for R representation:
mps.doc <- htmlParse(link_data)

# get all the tables in mps.doc as data frames
mps.tabs <- readHTMLTable(mps.doc) 
```

## Links

Beispiel: [GiventheData](http://giventhedata.blogspot.de/2012/08/r-and-web-for-beginners-part-iii.html)

[Five easy steps for webscraping](http://www.unt.edu/rss/class/Jon/Benchmarks/ScrapingData_L_JDS_Nov2013.pdf)

## Reference XML

```{r}
citation("XML")
```

## Reference `rvest`

```{r}
citation("rvest")
```

